package com.linkedin.venice.controller;

import com.linkedin.venice.controlmessage.ControlMessageHandler;
import com.linkedin.venice.controlmessage.StatusUpdateMessage;
import com.linkedin.venice.exceptions.VeniceException;
import com.linkedin.venice.job.Job;
import com.linkedin.venice.job.JobAndTaskStatus;
import com.linkedin.venice.job.JobRepository;
import com.linkedin.venice.job.OfflineJob;
import com.linkedin.venice.job.Task;
import com.linkedin.venice.meta.MetadataRepository;
import com.linkedin.venice.meta.Store;
import com.linkedin.venice.meta.Version;
import com.linkedin.venice.meta.VersionStatus;
import java.util.concurrent.atomic.AtomicInteger;
import org.apache.log4j.Logger;


/**
 * Venice job manager to handle all of control messages to update job/task status and do actions based the status
 * change.
 */
public class VeniceJobManager implements ControlMessageHandler<StatusUpdateMessage> {
  private static final Logger logger = Logger.getLogger(VeniceJobManager.class);
  private final JobRepository jobRepository;
  private final MetadataRepository metadataRepository;
  private final AtomicInteger idGenerator = new AtomicInteger(0);
  private final int epoch;

  public VeniceJobManager(int epoch, JobRepository jobRepository, MetadataRepository metadataRepository) {
    this.epoch = epoch;
    this.jobRepository = jobRepository;
    this.metadataRepository = metadataRepository;
  }

  public void startOfflineJob(String kafkaTopic, int numberOfPartition, int replicaFactor) {
    OfflineJob job = new OfflineJob(this.generateJobId(), kafkaTopic, numberOfPartition, replicaFactor);
    jobRepository.startJob(job);
  }

  @Override
  public void handleMessage(StatusUpdateMessage message) {
    jobRepository.lock();
    try {
      // TODO Right now, for offline-push, there is only when job running for each version. Should be change to get job
      // by job Id when H2V can get job Id and send it thourgh kafka control message.
      Job job = jobRepository.getRunningJobOfTopic(message.getKafkaTopic()).get(0);
      if (!job.getStatus().equals(JobAndTaskStatus.STARTED)) {

        throw new VeniceException(
            "Can not handle message:" + message.getMessageId() + ". Job has not been started:" + generateJobId());
      }
      //Update task status at first.
      Task task =
          new Task(this.getTaskId(message), message.getPartitionId(), message.getInstanceId(), message.getStatus());
      jobRepository.updateTaskStatus(job.getJobId(), task);
      logger.info("Update status of Task:" + task.getTaskId() + " to status:" + task.getStatus());
      //Check the job status after updating task status to see is the whole job completed or error.
      JobAndTaskStatus status = job.checkJobStatus();
      if (status.equals(JobAndTaskStatus.COMPLETED)) {
        logger.info("All of task are completed, mark job as completed too.");
        handleJobComplete(job);
      } else if (status.equals(JobAndTaskStatus.ERROR)) {
        logger.info("Some of tasks are failed, mark job as failed too.");
        handleJobError(job);
      }
    } finally {
      jobRepository.unlock();
    }
  }

  private void handleJobComplete(Job job) {
    //Do the swap. Change version to active so that router could get the notification and sending the message to this version.
    Store store = metadataRepository.getStore(Version.parseStoreFromKafkaTopicName(job.getKafkaTopic()));
    int versionNumber = Version.parseVersionFromKafkaTopicName(job.getKafkaTopic());
    store.updateVersionStatus(versionNumber, VersionStatus.ACTIVE);
    store.setCurrentVersion(versionNumber);
    metadataRepository.updateStore(store);
    jobRepository.stopJob(job.getJobId(), false);
    //TODO Archive job regularly instead of archive it immediately after being stopped.
    jobRepository.archiveJob(job.getJobId());
  }

  private void handleJobError(Job job) {
    //TODO do the roll back here.
    jobRepository.stopJob(job.getJobId(), true);
    //TODO Archive job regularly instead of archive it immediately after being stopped.
    jobRepository.archiveJob(job.getJobId());
  }

  /**
   * Id is composed by two part of integers. The higher 32 bytes is the epoch number and the lower 32 bytes is the
   * integer generated by AtomicInteger in this process. When this process(controller) is failed, the AtomicInteger will
   * start from 0 again. But a new epoch number should be used to ensure there is not duplicated id.
   * <p>
   * TODO Use some Linkedin common solution to get the global id here.
   *
   * @return
   */
  public long generateJobId() {
    long id = epoch;
    id = id << 32;
    int generatedId = idGenerator.incrementAndGet();
    id = id | generatedId;
    return id;
  }

  //TODO for off-line push, the task should be identified by job+partition+instance. Will use another taskId for stream job.
  public String getTaskId(StatusUpdateMessage message) {
    return message.getJobId() + "_" + message.getPartitionId() + "_" + message.getInstanceId();
  }

  public JobRepository getJobRepository() {
    return jobRepository;
  }

  public MetadataRepository getMetadataRepository() {
    return metadataRepository;
  }
}
